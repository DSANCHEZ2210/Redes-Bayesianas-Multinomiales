---
format:
   html:
     toc: true
     html-math-method: katex
     embed-resources: true
     self-contained-math: true
     df-print: kable
---

# Insatalamos la libreria bnlearn esto porque  incluye varios algoritmos para la estructura de redes bayesianas con variables discretas o continuas

```{r}
##install.packages("bnlearn")
##install.packages("dplyr")
```
#La mandamos a llamar

```{r}
library("bnlearn")

```

# Leemos nuestros datos finales (despues de limpiarlos)

```{r}
data = read.csv("df_final_py.csv", stringsAsFactors = TRUE)
head(data)
```

Llamamos la libreria dplyr esto para dropear algunas columnas. Vamos a dropear las columnas uso_metro, uso_autobus y uso_auto. Esto porque ya tenemos la columnas de transporte_publico. El cual contiene si se fue en auto, autobus, metro, etc. 
```{r}
library(dplyr)
```


```{r}
data <- data %>%
  select(-uso_autobus, -uso_metro, -uso_auto)
```

Tambien dropearemos los id ya que no lo necesitamos. 

```{r}
data <- data %>%
  select(-id_via, -id_soc, -id_hog, -id_viv )


```


```{r}
names(data)
```

ya tenemos nuestros datos bien como se puede ver a continuacion

```{r}
head(data)
```

Aqui cambiamos el nombre de nuestras variables por una letra o 2 letras, esto para facilitar nuestra DAG. 
```{r}
names(data) <- c("NP", "O","D", "S","E", "NE", "T", "DV")
```

Nombre de las Variables:
NP = Numero de personas en la vivienda
O = Origen
D = Destino
S = Sexo
E = Estrato
NE = Nivel de Estudios 
T =  Transporte publico  (Tambien hay transporte no publico pero es el nombre de la variable)
DV = Duracion de Viaje en Minutos

```{r}
head(data)
```

Aqui vamos a crear una nueva columna que la vamos a poner DV60, esto para discretizar la variable. Esto lo utilizaremos mas adelante para la query 3:

```{r}
data$DV60 <- factor(ifelse(data$DV > 60, "1", "0"), levels = c("0","1"))
```

Verificamos si se hizo: 
```{r}
head(data)
```

Ahora dropearemos CV60 esto porque no la utilizaremos, utilizaremos la DV60 a la cual ahora la renombraremos DV. Entonces la nueva DV sera la DV60. 

```{r}
data <- data %>%
  select(-DV )
```

Lo verificamos 
```{r}
head(data)
```

Le cambiamos el nombre de DV60 a DV:
```{r}
names(data) <- c("NP", "O","D", "S","E", "NE", "T", "DV")
```

Lo volvemos a verificar:

```{r}
head(data)
```


## Propuestas de DAGs
Llamamos la libreria Rgraphviz esto para verlo graficamente 
```{r}
##install.packages("BiocManager")
##BiocManager::install("Rgraphviz")
```
1) Primera DAG propuesta

creamos los nodos

```{r}
dag1 = empty.graph(nodes = c("NP", "O", "D", "S", "E", "NE", "T", "DV"))
```

Creamos la matriz de relaciones 

```{r}
arc_set = matrix(c("S", "NE",
                   "E", "NE",
                   "E", "T",
                   "E", "NP",
                   "T", "D",
                   "D", "O",
                   "D", "DV",
                   "O", "DV"), byrow = TRUE, ncol = 2,
                 dimnames = list(NULL, c("from", "to")))

```

Aqui lo podemos ver los nodos padres son los que estan en la columan de from y los nodos hijos en la columna de to. 

```{r}
arc_set
```

```{r}
arcs(dag1) = arc_set
```

Aqui vamos a ver la distribucion global de la DAG1 

```{r}
dag1
```
Y aqui vamos a ver la DAG1 graficamente

```{r}
graphviz.plot(dag1, shape = "ellipse")
```

2) DAG2 Propuesta

Cramos los nodos 

```{r}
dag2 = empty.graph(nodes = c("NP", "O", "D", "S", "E", "NE", "T", "DV"))
```

Creamos las relaciones

```{r}
arc_set1 = matrix(c("S", "NE",
                    "S", "T",
                   "E", "NE",
                   "E", "T",
                   "E", "NP",
                   "T", "D",
                   "D", "O",
                   "D", "DV",
                   "O", "DV"), byrow = TRUE, ncol = 2,
                 dimnames = list(NULL, c("from", "to")))
```


```{r}
arc_set1
```


```{r}
arcs(dag2) = arc_set1
```


```{r}
dag2
```

```{r}
graphviz.plot(dag2, shape = "ellipse")
```


3) DAG 3 Propuesta

Creamos los nodos

```{r}
dag3 = empty.graph(nodes = c("NP", "O", "D", "S", "E", "NE", "T", "DV"))
```

Creamos la matriz de realciones

```{r}
arc_set3 = matrix(c("S", "NE",
                   "E", "NE",
                   "E", "T",
                   "E", "NP",
                   "E", "D",
                   "NP", "O",
                   "T", "D",
                   "D", "O",
                   "D", "DV",
                   "O", "DV"), byrow = TRUE, ncol = 2,
                 dimnames = list(NULL, c("from", "to")))
```

Aqui vemoa las realciones de from a to

```{r}
arc_set3
```
```{r}
arcs(dag3) = arc_set3
```


```{r}
dag3
```

```{r}
graphviz.plot(dag3, shape = "ellipse")
```

```{r}
sapply(data[, c("NP","O","D","S","E","NE","T","DV")], class)
# Debe imprimir: factor para NP,O,D,S,E,NE,T y numeric para DV (opción B)
# o factor para todas (opción A)

```


# Comparacion de DAG
Ahora teniendo las 3 DAGs propuestas veremos cual es la mejor DAG con la funcion de BIC. En la libreria bnlearn entre mayor mejor es la DAG.

Primero debemos de hacer nuestras variables factor con este codigo. Ya que la libreria bn learn no acepta integer y todas nuestras variables son integer.

```{r}
data[] <- lapply(data, factor) #columnas a factor
str(data)


```

El score de la DAG1 usando BIC es de:
```{r}
score(dag1, data = data, type = "bic")


```

El score de la DAG2 usando BIC es de:
```{r}
score(dag2, data = data, type = "bic")
```

El score de la DAG2 usando BIC es de:
```{r}
score(dag3, data = data, type = "bic")
```

Aquí vemos que la mejor DAG fue la segunda. Pero utilizaremos un algoritmo llamado Hill Climbing para que nos diga con nuestros datos cual es la mejor DAG.

## Mejor DAG: Hill Climbing

```{r}
best_dag = hc(data)
```

```{r}
modelstring(best_dag)
```
Aqui lo comprobaremos score utilizando el BIC

```{r}
score(best_dag, data = data, type = "bic")
```

Claramente se ve que hay una gran mejora en nuestro score. 

Aqui la veremos graficamente: 

```{r}
graphviz.plot(best_dag, shape = "ellipse")
```

## Queries

Ya para responder nuestra queries utilizaremos lal ibreria bnlearn, usamos el bn.fit para que me ajuste los parametros a nuestra red bayesiana que va a ser la best_dag ya que esta tiene mejor score.

```{r}
bn = bn.fit(best_dag, data = data)
```

Query 1:

¿Cuál es la probabilidad de que una persona que vive en una vivienda en la que habitan de 2 a 5 personas, use de transporte público el metro o autobús como principal medio de viaje?

Lo que hace el cpquery es que hace un muestreo de Monte Carlo.
Ahora en el evento es lo que queremos sacar la probabilidad dado a la evidencia. Y la evidencia es lo que ya sabemos. Entonces con este codigo vamos a meter el evento y la evidencia. Nuestra n es de 10^6, ya que es el integer las grande. 
```{r}
cpquery(bn, event = (T=="5" | T == "8"), evidence = ((NP == "2")|(NP == "3")|(NP == "4")|(NP == "5")) , n = 10^6)
```


Query 2:¿Cuál es la probabilidad de que el viaje del hogar al trabajo dure más de 60 minutos si la persona viaja en coche?


```{r}
cpquery(bn, event = (O =="2" & D == "3" & DV == "1"), evidence = (T== "1") , n = 10^6)
```


Query 3: ¿Cuál es la probabilidad de que una mujer, use el colectivo/micro dado que es de estrato alto?
```{r}
cpquery(bn, event = (S =="1" & T == "2" ), evidence = (E== "4") , n = 10^6)
```

Query 4: ¿Cuál es la probabilidad de que una persona con Licenciatura, Maestría o Doctorado utilice transporte público como medio principal de viaje para ir al trabajo?

```{r}
cpquery(bn, event = (T=="2" | T == "5" | T == "6" | T== "8" | T== "10" | T == "11" | T == "12" | T== 13), evidence = ((NE == "8")|(NE == "9")) , n = 10^6)

```


